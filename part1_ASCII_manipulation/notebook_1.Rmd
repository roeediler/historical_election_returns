---
title: "Dealing With Historical US Election Data - Part 1"
subtitle: "A comprehensive guide to processing, cleaning, and analyzing complex data"
author: "Roee Diler"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: united
    toc: yes
    toc_depth: 3
    toc_float: yes
    df_print: paged
  pdf_document:
    toc: yes
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
options(scipen = 999)
```

# Introduction

This notebook processes election returns data from the ICPSR dataset. It reads ASCII files, cleans the data, and generates CSV files for further analysis.

It was part of an economic history project that I worked on with a professor at the Hebrew University of Jerusalem. The goal was to analyze historical election data to understand voting patterns and political trends in the United States.

## ICPSR and Historical Election Data

The **Inter-university Consortium for Political and Social Research (ICPSR)** is a major archive of social science data, providing access to a wide range of datasets. One of its significant contributions is the **United States Historical Election Returns, 1824-1968 (ICPSR 1)**, a collection of county-level election returns spanning nearly 150 years.

This dataset includes over **90% of all elections** for the offices of **president, governor, U.S. senator, and U.S. representative** between 1824 and 1968. It covers both **regular and special elections**, documenting results for **all parties, candidates, and independent contenders**â€”including more than 1,000 unique political party names. The dataset provides a valuable resource for researchers studying **historical voting patterns, political party evolution, and electoral trends** across the United States.

These data sets were stored in **ASCII (American Standard Code for Information Interchange) format** which is a simple text-based format with accompanying **SAS setup files** that describe the structure of the data. The ASCII files contain raw data without metadata, while the SAS setup files provide information on **column positions, variable names, formats, and missing values**.

In R, these datasets can be imported using packages like **SAScii** and **asciiSetupReader**. We will examine both of these packages to determine the best approach for reading the ICPSR election data.

### Citation

Inter-university Consortium for Political and Social Research. *United States Historical Election Returns, 1824-1968.* Inter-university Consortium for Political and Social Research [distributor], 1999-04-26. <https://doi.org/10.3886/ICPSR00001.v3>.

## Required Packages

Load necessary libraries using `pacman` for package management.

```{r load-packages}
rm(list = ls())  # Clear workspace

library(pacman)
p_load(data.table, tidyverse, asciiSetupReader, SAScii, naniar, Hmisc, rlist)
```

## Define Paths

Set up directory paths dynamically based on the script location.

```{r define-paths}
script_path <- dirname(rstudioapi::getSourceEditorContext()$path)
basic_path <- script_path
data_path <- file.path(basic_path, "data")
icpsr_path <- file.path(data_path, "ICPSR/ICPSR_00001")
```

# Data Import and Presentation

## Read the First Dataset

Let's start by reading the first dataset (DS0001) from the ICPSR election data. We will use the `read.SAScii` function from the `SAScii` package to import the data and review the first few rows.

```{r SAScii, results='hide'}
txt_path <- file.path(icpsr_path, "/DS0001/00001-0001-Data.txt")
sas_path <- file.path(icpsr_path, "/DS0001/00001-0001-Setup.sas")

elec_data001 <- read.SAScii(txt_path, sas_path) %>% as.data.table()
```

```{r}
elec_data001 %>% head()
```

We can see that the data is in a wide format with multiple columns representing different variables. The column names are not descriptive, and the data is not in a format suitable for analysis.

Let's try the `asciiSetupReader` package to read the data and extract variable names and missing values.

```{r}
elec_data001 <- read_ascii_setup(txt_path, sas_path) %>% as.data.table()
elec_data001 %>% head()
```

The column names are correct, **but 10 columns are missing**.

Since neither package provides a complete solution, we will need to combine the functionality of both to read the data correctly.

We will create some functions that will help us process the data correctly and set up a pipeline to generate a well organized data set.

# Define Functions for Data Processing

## Outline of Data Processing Steps

To correctly process the ICPSR election data, we need a series of functions to:

1.  **Define Paths**: Dynamically locate the ASCII data and setup files for each dataset.
2.  **Read the Raw Data**: Load the dataset using the `read.SAScii` function and extract variable names and missing values dictionary using `parse_setup` function.
3.  **Adjust Missing Data**: Identify and replace missing values in key columns.
4.  **Reshape Data**: Transform the dataset into a long format for easier analysis.
5.  **Merge Data**: Attach variable names and missing value dictionary to the main dataset.
6.  **Automate Processing**: Wrap all the above steps into a single function to process multiple datasets efficiently.

## Define Functions

### Function: Define Paths

Generates file paths dynamically based on the dataset number.

```{r}
define_paths <- function(file_num) {
  list(
    ascii_path = file.path(icpsr_path, paste0("DS0", file_num, "/00001-0", file_num, "-Data.txt")),
    sas_path = file.path(icpsr_path, paste0("DS0", file_num, "/00001-0", file_num, "-Setup.sas"))
  )
}
```

### Function: Read Raw Data

Reads ICPSR data using `read.SAScii`, extracts variable names, and missing values dictionary using `parse_setup` function.

```{r}
raw_read <- function(paths) {
  icpsr_data <- read.SAScii(paths$ascii_path, paths$sas_path) %>% as.data.table()
  setup_file <- parse_setup(paths$sas_path)
  var_names <- setup_file[[1]] %>% as.data.table() %>% select(column_number, column_name)
  missing <- setup_file[[3]] %>% as.data.table()
  
  list(data = icpsr_data, var_names = var_names, missing = missing)
}
```

### Function: Handle Missing IDs

Replaces missing values with `NA` in the `V1` and `V3` columns, representing the state and county identifiers.

```{r}
change_missing_ids <- function(full_list) {
  icpsr_data <- full_list$data
  missing <- full_list$missing
  
  for (col in c("V1", "V3")) {
    if (col %in% missing$variable) {
      missing_values <- as.numeric(missing[variable == col, values])
      icpsr_data[get(col) %in% missing_values, (col) := NA]
    }
  }
  full_list$data <- icpsr_data
  return(full_list)
}
```

### Function: Reshape Data

Transforms data from wide to long format and adds a source identifier.

```{r}
melt_icpsr <- function(full_list, file_num) {
  full_list$data <- melt(full_list$data, id.vars = c("V1", "V2", "V3"))
  full_list$data[, source := paste0("DS0", file_num)]
  return(full_list)
}
```

### Function: Merge Variables

Merges variable names and missing values into the dataset.

```{r}
merge_icpsr <- function(full_list) {
  full_list$data <- merge(full_list$data, full_list$var_names, 
                          by.x = "variable", by.y = "column_number", all.x = TRUE)
  full_list$data <- merge(full_list$data, full_list$missing, 
                          by = "variable", all.x = TRUE)
  return(full_list$data)
}
```

### Function: Process ICPSR Data

Combines all previous steps into a single pipeline.

```{r}
icpsr_process <- function(file_num) {
  file_num %>% 
    define_paths() %>% 
    raw_read() %>% 
    change_missing_ids() %>% 
    melt_icpsr(file_num = file_num) %>% 
    merge_icpsr()
}
```

# Process and Read All Files

## Process ICPSR Data

We will now process all ICPSR datasets using the defined functions and store the cleaned data in a list. Exclude problematic datasets that require manual processing.

```{r, results='hide'}
# Get ICPSR 0001 files list
filenames <- list.files(path = icpsr_path, full.names = FALSE)
filenames <- str_subset(filenames, "DS0")
filenames <- gsub("DS0", "", filenames) 
# delete the problematic data sets that we will process manually and party codes file
filenames <- filenames[!filenames %in% c("001", "012", "091", "144", "194", "202", "204")]

# Read and clean ICPSR 0001 files
data_list <- lapply(filenames, icpsr_process)
```

## Manual Error Corrections for Multiple Datasets

### Data Set 1: Correcting Missing Variable Names

-   The function `parse_setup` does not read all the vars names, we will add them manually.

```{r, results='hide'}
# Define the file number for the dataset
file_num <- "001"

# Load the dataset and process missing IDs
full_list <- file_num %>% define_paths() %>% 
  raw_read() %>% 
  change_missing_ids()
```

```{r}
# Extract the dataset and variable names from the processed list
icpsr_data <- full_list$data
var_names <- full_list$var_names

# Display the first 10 variable names to identify missing values
head(var_names, 10)
```

The function `parse_setup` does not correctly read all variable names. Specifically, it misses congressional district number variables between V6 and V24. We manually add these missing variable names.

```{r}
# Define the missing variable names along with their respective identifiers
var_names_add <- data.table(
  column_number = c("V6", "V8", "V10", 
                    "V12", "V14", "V16", 
                    "V18", "V20", "V22", "V24"), 
  column_name = var_names$column_name[5:14]  # Extract the missing names from the dataset
)

# Manually assign the correct congressional district numbers to the corresponding variables
var_names[5:14 , column_name := 
            c("CONG_DIST_NUMBER_1827", "CONG_DIST_NUMBER_1831", 
              "CONG_DIST_NUMBER_1834", "CONG_DIST_NUMBER_1836", 
              "CONG_DIST_NUMBER_1839", "CONG_DIST_NUMBER_1843", 
              "CONG_DIST_NUMBER_1847", "CONG_DIST_NUMBER_1851", 
              "CONG_DIST_NUMBER_1855", "CONG_DIST_NUMBER_1859")]

# Append the newly defined variables to the variable names dataset
var_names <- rbind(var_names, var_names_add)

# Ensure that variables are ordered numerically by their column number
var_names <- var_names[order(as.numeric(gsub("V", "", column_number))) , ]

# Remove the temporary dataset to free memory
rm(var_names_add)

# Display the first 10 variable names to verify the changes
head(var_names, 10)
```

Next, we define missing value codes for the newly added variables and append them to the existing missing value definitions.

```{r}
# Handle missing value definitions for the newly added variables
missing <- full_list$missing

# Define missing value codes for the new variables
missing_add <- data.table(
  variable = c("V6", "V8", "V10", 
               "V12", "V14", "V16", 
               "V18", "V20", "V22", "V24"), 
  values = c(rep("0000099", 9), "9999999")
)

# Append missing value definitions to the existing missing dataset
missing <- rbind(missing, missing_add)

# Remove temporary dataset to free memory
rm(missing_add)
```

Finally, we update the full list with corrected variable names and missing value definitions, complete the data processing pipeline, and store the corrected dataset in the list for further analysis.

```{r}
# Update the full list with corrected variable names and missing value definitions
full_list <- list(data = icpsr_data, var_names = var_names, missing = missing)

# Complete the data processing pipeline
d1 <- full_list %>% melt_icpsr(file_num = file_num) %>% merge_icpsr()

# Store the cleaned and processed dataset in a list for further analysis
data_list[[1]] <- d1

# Clean up the workspace by removing unnecessary objects
rm(d1, full_list, icpsr_data, var_names, missing)

```

### Data Set 12: Correcting Variable Case Sensitivity Issue

-   The variable `V444` in the sas setup file was written as `v444`, we will fix it.

```{r, results='hide'}
# Define the file number
file_num <- "012"

# Read and preprocess the dataset
full_list <- file_num %>% define_paths %>% raw_read() %>% 
  change_missing_ids()

# Fix the variable name case issue (v444 -> V444)
full_list$var_names <- full_list$var_names[column_number == "v444", column_number := "V444"]

# Define missing values for the corrected variable
missing_add <- data.table(variable = "V444", values = "9999999")
full_list$missing <- rbind(full_list$missing, missing_add)
rm(missing_add)

# Process the dataset

d12 <- full_list %>% 
  melt_icpsr(., file_num = file_num) %>% 
  merge_icpsr()

# Store the processed dataset
data_list[[12]] <- d12

# Clean up workspace
rm(d12, full_list, file_num)
```

### Data Set 91: Handling Null Values to Prevent Data Corruption

-   There are null values in the data set which causes the function to read all the data afterward as null values, we will use alternative data set without null values.

This is the warning message that we received when trying to read the data set with null values:

> Warning: line 46 appears to contain an embedded nul:

```{r, results='hide'}
# Define the file number
file_num <- "091"

# Define file paths to use an alternative dataset without null values
ascii_path = paste0(data_path, "/icpsr_no_nul/DS0", file_num, "_no_nul.txt")
sas_path = paste0(icpsr_path, "/DS0", file_num, "/00001-0", file_num, "-Setup.sas")

paths <- list(ascii_path = ascii_path, sas_path = sas_path)

# Read and preprocess the dataset using alternative files

d91 <- paths %>% raw_read() %>% 
  change_missing_ids() %>% 
  melt_icpsr(., file_num = file_num) %>% 
  merge_icpsr()

# Store the processed dataset
data_list[[91]] <- d91

# Clean up workspace
rm(d91, ascii_path, sas_path, paths, file_num)
```

### Data Set 144: Removing Duplicate Variable (V4)

-   The variable `V4` duplicates the variable `V2` which is the name of the county, we will remove it.

```{r, results='hide'}
# Define the file number
file_num <- "144"

# Read and preprocess the dataset
full_list <- file_num %>% define_paths %>% raw_read() %>% 
  change_missing_ids() 

# Remove duplicate variable V4 (which duplicates county name from V2)
full_list$data <- full_list$data %>% select(-V4)

# Process the dataset

d144 <- full_list %>% 
  melt_icpsr(., file_num = file_num) %>% 
  merge_icpsr()

# Store the processed dataset
data_list[[144]] <- d144

# Clean up workspace
rm(d144, full_list, file_num)
```

### Data Set 194: Fixing Mislabeled Variables in SAS Setup File

-   The SAS setup file has typo errors in the LABEL section in the V3 version from 1999 that we used.

```{r, results='hide'}
# Define the file number
file_num <- "194"

# Read and preprocess the dataset
full_list <- file_num %>% define_paths() %>% 
  raw_read() %>% 
  change_missing_ids()
```

```{r}
# Extract dataset and variable names
icpsr_data <- full_list$data
var_names <- full_list$var_names

# Identify mislabeled variables
var_names[c(53:56, 123:127, 153:155) , ]
```

As we can see, the variable names `V55` and `V126` are missing. We will manually fix these errors.

```{r}
var_names_add <- data.table(column_number = c("V55", "V126"), 
                            column_name = c("X946_4_S_SEN_9001_VOTE", "X952_3_G_CONG_0749_VOTE"))
var_names[column_number == "V156", column_name := "X956_1_G_PRES_0913_VOTE"]
var_names <- rbind(var_names, var_names_add)
rm(var_names_add)

# Define missing values for corrected variables
missing <- full_list$missing
missing_add <- data.table(variable = c("V55", "V126"), 
                          values = c(rep("9999999", 2)))
missing <- rbind(missing, missing_add)
rm(missing_add)

# Update full list with corrections
full_list <- list(data = icpsr_data, var_names = var_names, missing = missing)

d194 <- full_list %>% melt_icpsr(file_num = file_num) %>% merge_icpsr()

# Store the processed dataset
data_list[[194]] <- d194

# Clean up workspace
rm(d194, full_list, icpsr_data, var_names, missing, file_num)
```

### Data Set 202: Handling Incorrect Label Formatting in SAS Setup File

-   The SAS setup file has typo errors in the LABEL section in the V3 version from 1999 that we used. The begging of the LABEL section was suppose to be `*/`, but it was `/*`. In this case the other function `read_ascii_setup` read the data well so we used it.

```{r}
# Define the file number
file_num <- "202"

# Define file paths
paths <- file_num %>% define_paths()

# Read dataset using an alternative parsing function due to SAS label formatting issue
icpsr_data <- read_ascii_setup(paths$ascii_path, paths$sas_path) %>% as.data.table()
setup_file <- parse_setup(paths$sas_path)

# Extract variable names and missing value definitions
var_names <- setup_file[[1]] %>% as.data.table() %>% select(column_number, column_name)
missing <- setup_file[[3]] %>% as.data.table()

# Rename key variables for consistency
setnames(icpsr_data, 
         old = c("ICPR_STATE_CODE", "COUNTY_NAME", "IDENTIFICATION_NUMBER"), 
         new = c("V1", "V2", "V3"))

# Combine dataset components
full_list <- list(data = icpsr_data, var_names = var_names, missing = missing)

# Process and reshape data
full_list <- full_list %>% change_missing_ids() %>% melt_icpsr(file_num = file_num)

# Merge metadata
full_list$data <- merge(full_list$data, full_list$var_names, 
                        by.x = "variable", by.y = "column_name", all.x = TRUE)
full_list$data <- merge(full_list$data, full_list$missing, 
                        by.x = "column_number", by.y = "variable", all.x = TRUE)

# Rename columns for clarity
setnames(full_list$data, old = c("column_number", "variable"), new = c("variable", "column_name"))

# Ensure consistency with other datasets
full_list$data <- full_list$data %>% select(names(data_list[[1]]))

# Store the processed dataset
data_list[[202]] <- full_list$data

# Clean up workspace
rm(icpsr_data, var_names, missing, paths, setup_file, full_list, file_num)
```

# Final Step: Merging All Processed Data

We will now merge all processed datasets into a single dataset and save it as a CSV file for further analysis.

```{r}
icpsr_data <- rbindlist(data_list)

# Save the merged dataset to a CSV file
fwrite(icpsr_data, paste0(data_path, "/icpsr_long_raw.csv"))
```

A quick summary of the final dataset:

```{r}
skimr::skim(icpsr_data)
```


